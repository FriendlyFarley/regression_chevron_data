# -*- coding: utf-8 -*-
"""Rice Datathon Cheveron.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1iW9XXv9KZ2Aht9VgyLD9Wd6NqpiRqzAI

# Imports
"""

import pandas as pd
import math
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.preprocessing import OneHotEncoder
from sklearn.metrics import r2_score
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error

# prompt: import r2 score

from sklearn.metrics import r2_score

"""# Preprocessing and Visualization"""

df = pd.read_csv('/content/training.csv')
df

#############################################

df2 = pd.read_csv('/content/scoring.csv')
df2

df.tail(30000)

# Remove the inequality from NOVRATSA
df['Number of Vehicles Registered at the Same Address'] = df['Number of Vehicles Registered at the Same Address'].astype(str).str.replace(r'[<>=]', '', regex=True)
print(df['Number of Vehicles Registered at the Same Address'])
# Convert the column to numeric, coercing errors to NaN
df['Number of Vehicles Registered at the Same Address'] = pd.to_numeric(df['Number of Vehicles Registered at the Same Address'], errors='coerce')

##########################################################

df2['Number of Vehicles Registered at the Same Address'] = df2['Number of Vehicles Registered at the Same Address'].astype(str).str.replace(r'[<>=]', '', regex=True)
print(df2['Number of Vehicles Registered at the Same Address'])
df2['Number of Vehicles Registered at the Same Address'] = pd.to_numeric(df2['Number of Vehicles Registered at the Same Address'], errors='coerce')

print(df['Number of Vehicles Registered at the Same Address'])

# Find indices of NaN values in the specified column
nan_indices = df[df['Number of Vehicles Registered at the Same Address'].isnull()].index

nan_indices

# Get indices where 'Number of Vehicles Registered at the Same Address' is NOT NaN
not_nan_indices = df[~df['Number of Vehicles Registered at the Same Address'].isnull()].index
not_nan_indices

######################################################

nan_indices2 = df2[df2['Number of Vehicles Registered at the Same Address'].isnull()].index

nan_indices2

not_nan_indices2 = df2[~df2['Number of Vehicles Registered at the Same Address'].isnull()].index
not_nan_indices2

df['Number of Vehicles Registered at the Same Address'].iloc[nan_indices] = 4

###################################################################

df2['Number of Vehicles Registered at the Same Address'].iloc[nan_indices2] = 4
#df['Number of Vehicles Registered at the Same Address'].iloc[nan_indices]

# Observation of features vs target variable to verify a linear realationship
for col in df.columns:
    plt.figure(figsize=(5,3))
    sns.scatterplot(x=df[col], y= df['Vehicle Population'])
    plt.title(f'Relationship between {col} and Vehicle Population')
    #plt.savefig(col)
    plt.show()

"""# Data Cleaning and Analysis"""

# Check the number of unique values in each column

for column in df.columns:
  unique_count = df[column].nunique()
  print(f"Column '{column}' has {unique_count} unique values.")

# prompt: show me all the unique values in the column date

print(df['Date'].unique())

print(df['Model Year'].unique())

# Converts nan value in Model Year to median
median_model_year = df['Model Year'].median()
df['Model Year'] = df['Model Year'].fillna(median_model_year)
print(df['Model Year'].unique())

###########################################

median_model_year2 = df2['Model Year'].median()
df2['Model Year'] = df2['Model Year'].fillna(median_model_year2)
print(df2['Model Year'].unique())

#Drop region column
df = df.drop(columns=['Region'])

df2 = df2.drop(columns=['Region'])

# prompt: replace 'Unknown' with median values in 'GVWR Class', 'Electric Mile Range', 'Fuel Type'

# Replace 'Unknown' with median values for specified columns

for col in ['GVWR Class', 'Electric Mile Range', 'Fuel Type']:
    # Calculate the median for the current column, excluding 'Unknown' values
    median_value = df[df[col] != 'Unknown'][col].mode()[0]

    # Replace 'Unknown' values with the calculated median
    df[col] = df[col].replace('Unknown', median_value)

# Repeat the same process for the df2 DataFrame
for col in ['GVWR Class', 'Electric Mile Range', 'Fuel Type']:
    median_value = df2[df2[col] != 'Unknown'][col].mode()[0]
    df2[col] = df2[col].replace('Unknown', median_value)

df

print(df['Electric Mile Range'].unique())

print(df['Fuel Technology'].unique())

print(df['Fuel Type'].unique())

print(df['GVWR Class'].unique())

print(df['Vehicle Category'].unique())

print(df['Date'].unique())

"""# Seperating Data"""

numerical_df = df.select_dtypes(exclude=['object']).drop(columns=['Vehicle Population'], errors='ignore')
categorical_df = df.select_dtypes(include=['object'])

#####################################################

numerical_df2 = df2.select_dtypes(exclude=['object']).drop(columns=['Vehicle Population'], errors='ignore')
categorical_df2 = df2.select_dtypes(include=['object'])
# replicate this process using the scoring.csv file

categorical_encoded = pd.get_dummies(categorical_df, drop_first=True)
encoder = OneHotEncoder(drop='first', sparse_output=False)
categorical_encoded = pd.DataFrame(encoder.fit_transform(categorical_df))
categorical_encoded.columns = encoder.get_feature_names_out()

##################################################

categorical_encoded2 = pd.get_dummies(categorical_df2, drop_first=True)
encoder2 = OneHotEncoder(drop='first', sparse_output=False)
categorical_encoded2 = pd.DataFrame(encoder2.fit_transform(categorical_df2))
categorical_encoded2.columns = encoder2.get_feature_names_out()

X = pd.concat([numerical_df, categorical_encoded], axis=1)

###################################################

X2 = pd.concat([numerical_df2, categorical_encoded2], axis=1)

y = df['Vehicle Population']


y2 = df2['Vehicle Population']

"""# Model Creation"""

rf_model = RandomForestRegressor()
rf_model.fit(X, y)

rf_model = RandomForestRegressor()
rf_model.fit(X, y)

y_pred_rf = rf_model.predict(X)
mse_rf = mean_squared_error(y, y_pred_rf)
r2_rf = r2_score(y, y_pred_rf)

print(f"Random Forest - Root Mean Squared Error: {np.sqrt(mse_rf)}")
print(f"Random Forest - R² Score: {r2_rf}")

len(y_pred_rf)

y_pred_rf = rf_model.predict(X2)
mse_rf = mean_squared_error(y2, y_pred_rf)
r2_rf = r2_score(y2, y_pred_rf)

print(f"Random Forest - Root Mean Squared Error: {np.sqrt(mse_rf)}")
print(f"Random Forest - R² Score: {r2_rf}")

# Create a DataFrame from y_pred_rf
y_pred_rf_df = pd.DataFrame({'predicted_vehicle_population': y_pred_rf})

# Save the DataFrame to a CSV file
y_pred_rf_df.to_csv('y_pred_rf.csv', index=False)

